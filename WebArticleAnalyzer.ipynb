{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3QQ2wbB2cQl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import shutil\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "os: Used for interacting with the operating system, such as reading\n",
        "\n",
        "\n",
        "files and directories.\n",
        "\n",
        "re: Provides regular expression support for pattern matching in text (e.g., finding personal pronouns).\n",
        "\n",
        "nltk: Natural Language Toolkit for text processing tasks like tokenization and stopword removal.\n",
        "\n",
        "requests: Used to send HTTP requests to fetch webpage content.\n",
        "\n",
        "pandas: For data manipulation and handling Excel files.\n",
        "\n",
        "BeautifulSoup: A library for parsing HTML and extracting specific content from web pages.\n",
        "\n",
        "word_tokenize, sent_tokenize: Functions from NLTK to split text into words and sentences.\n",
        "\n",
        "google.colab: Used for file uploads in Google Colab (optional if running locally).\n",
        "\n",
        "zipfile: For extracting ZIP files.\n",
        "\n",
        "shutil: For file operations like moving or copying files."
      ],
      "metadata": {
        "id": "j_LdyEQPFcBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')  # Ensure punkt resource is downloaded\n",
        "nltk.download('stopwords')  # Ensure stopwords resource is downloaded\n",
        "\n",
        "nltk.download('punkt_tab')  # Fixes the LookupError\n",
        "nltk.data.path.append('/usr/local/nltk_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrqpwPSBa91D",
        "outputId": "b6feefe9-fd3e-4ff0-8fc9-3e3ebc9a93e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk.download('punkt'): Downloads the punkt tokenizer models for word and sentence tokenization.\n",
        "\n",
        "nltk.download('punkt_tab'): Downloads additional tokenizer tables to fix the LookupError.\n",
        "\n",
        "nltk.data.path.append(...): Adds a custom path for NLTK data files."
      ],
      "metadata": {
        "id": "Y5M8sv6mFdsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload StopWords and MasterDictionary folders manually in Colab\n",
        "print(\"Please upload the StopWords and MasterDictionary folders as a ZIP file\")\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "yqeC5C--YDBN",
        "outputId": "8baef7d9-6cde-4bc5-cab8-3741f0ca6c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the StopWords and MasterDictionary folders as a ZIP file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a50b178a-d2df-4a42-a746-25bd90060935\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a50b178a-d2df-4a42-a746-25bd90060935\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving MasterDictionary-20250305T025258Z-001.zip to MasterDictionary-20250305T025258Z-001 (1).zip\n",
            "Saving StopWords-20250305T024631Z-001.zip to StopWords-20250305T024631Z-001 (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "files.upload(): Prompts the user to upload ZIP files in Google Colab.\n",
        "\n",
        "shutil.unpack_archive(): Extracts the uploaded ZIP files into the current directory."
      ],
      "metadata": {
        "id": "wTwDpzB8FjEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    shutil.unpack_archive(filename, './')"
      ],
      "metadata": {
        "id": "i9-vtGmwYFfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stopwords = set(): Initializes an empty set to store stopwords.\n",
        "\n",
        "os.listdir(stopwords_path): Lists all files in the StopWords folder.\n",
        "\n",
        "with open(...): Reads each file and adds its words to the stopwords set.\n",
        "\n",
        "stopwords.update(...): Updates the set with words from the file."
      ],
      "metadata": {
        "id": "F7MVYKPfFl2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Stopwords\n",
        "stopwords = set()\n",
        "stopwords_path = \"StopWords\"\n",
        "for filename in os.listdir(stopwords_path):\n",
        "    try:\n",
        "        with open(os.path.join(stopwords_path, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            stopwords.update(f.read().split())\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "8DhQ68bCYve1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive_words and negative_words: Sets to store positive and negative words.\n",
        "\n",
        "with open(...): Reads the positive and negative word files and updates the respective sets."
      ],
      "metadata": {
        "id": "R927M4UeFpLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Master Dictionary\n",
        "positive_words = set()\n",
        "negative_words = set()\n",
        "try:\n",
        "    with open(\"MasterDictionary/positive-words.txt\", 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        positive_words.update(f.read().split())\n",
        "    with open(\"MasterDictionary/negative-words.txt\", 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        negative_words.update(f.read().split())\n",
        "except Exception as e:\n",
        "    print(f\"Error reading Master Dictionary: {e}\")"
      ],
      "metadata": {
        "id": "opFs7a8RY5cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "files.upload(): Prompts the user to upload Input.xlsx.\n",
        "\n",
        "pd.read_excel(...): Reads the Excel file into a Pandas DataFrame."
      ],
      "metadata": {
        "id": "Du8bXl2xFrEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload Input.xlsx manually in Colab\n",
        "print(\"Please upload Input.xlsx\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Gg4C4gptZP_E",
        "outputId": "c126842f-f2bf-4b01-d0bc-01df0c6d2766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload Input.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d579658-c836-4dcf-844a-354508c49c01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d579658-c836-4dcf-844a-354508c49c01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Input.xlsx to Input.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load input URLs\n",
        "input_df = pd.read_excel(\"Input.xlsx\")"
      ],
      "metadata": {
        "id": "aPmhKuRLZSC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(url):\n",
        "    \"\"\"Extract article title and text from URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        title = soup.find('h1').get_text(strip=True) if soup.find('h1') else \"\"\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = ' '.join([p.get_text(strip=True) for p in paragraphs])\n",
        "        return title + \"\\n\" + article_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "3H_YzrrDZVaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requests.get(url): Fetches the webpage content.\n",
        "\n",
        "BeautifulSoup(...): Parses the HTML content.\n",
        "\n",
        "soup.find('h1'): Extracts the article title.\n",
        "\n",
        "soup.find_all('p'): Extracts all paragraphs.\n",
        "\n",
        "article_text: Combines the title and paragraphs into a single string."
      ],
      "metadata": {
        "id": "nVWVRL5HFujb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Remove stopwords and special characters.\"\"\"\n",
        "    words = word_tokenize(text.lower())\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords]\n",
        "    return words\n",
        "\n",
        "def analyze_sentiment(words):\n",
        "    \"\"\"Calculate sentiment scores.\"\"\"\n",
        "    pos_score = sum(1 for word in words if word in positive_words)\n",
        "    neg_score = sum(1 for word in words if word in negative_words)\n",
        "    polarity = (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
        "    subjectivity = (pos_score + neg_score) / (len(words) + 0.000001)\n",
        "    return pos_score, neg_score, polarity, subjectivity\n",
        "\n",
        "def compute_readability(text):\n",
        "    \"\"\"Calculate readability metrics.\"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    avg_sentence_length = len(words) / (len(sentences) + 0.000001)\n",
        "    complex_words = [word for word in words if sum(1 for c in word if c in 'aeiou') > 2]\n",
        "    percentage_complex = len(complex_words) / (len(words) + 0.000001)\n",
        "    fog_index = 0.4 * (avg_sentence_length + percentage_complex)\n",
        "    return avg_sentence_length, percentage_complex, fog_index, len(complex_words), len(words)\n",
        "\n",
        "def extract_personal_pronouns(text):\n",
        "    \"\"\"Count occurrences of personal pronouns.\"\"\"\n",
        "    pronouns = re.findall(r'\\b(I|we|my|ours|us)\\b', text, re.I)\n",
        "    return len(pronouns)"
      ],
      "metadata": {
        "id": "3XAdp8ifZXy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "word_tokenize(...): Splits the text into individual words.\n",
        "\n",
        "text.lower(): Converts text to lowercase for case-insensitive comparison.\n",
        "\n",
        "word.isalnum(): Filters out non-alphanumeric words (e.g., punctuation).\n",
        "\n",
        "word not in stopwords: Removes stopwords.\n",
        "\n",
        "pos_score: Counts positive words.\n",
        "\n",
        "neg_score: Counts negative words.\n",
        "\n",
        "polarity: Calculates the polarity score (ranges from -1 to +1).\n",
        "\n",
        "subjectivity: Calculates the subjectivity score (ranges from 0 to +1).\n",
        "\n",
        "sent_tokenize(...): Splits text into sentences.\n",
        "\n",
        "word_tokenize(...): Splits text into words.\n",
        "\n",
        "avg_sentence_length: Calculates the average number of words per sentence.\n",
        "\n",
        "complex_words: Identifies words with more than two syllables.\n",
        "\n",
        "fog_index: Computes the Gunning Fog Index for readability.\n",
        "\n",
        "re.findall(...): Uses regex to find personal pronouns (I, we, my, ours, us).\n",
        "\n",
        "re.I: Makes the search case-insensitive."
      ],
      "metadata": {
        "id": "uBBmSq1xFxob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_articles():\n",
        "    \"\"\"Process each URL and analyze the extracted text.\"\"\"\n",
        "    results = []\n",
        "    for _, row in input_df.iterrows():\n",
        "        url_id, url = row['URL_ID'], row['URL']\n",
        "        text = extract_text(url)\n",
        "        if text:\n",
        "            words = clean_text(text)\n",
        "            pos_score, neg_score, polarity, subjectivity = analyze_sentiment(words)\n",
        "            avg_sent_length, perc_complex, fog, complex_count, word_count = compute_readability(text)\n",
        "            pronoun_count = extract_personal_pronouns(text)\n",
        "            avg_word_length = sum(len(word) for word in words) / (len(words) + 0.000001)\n",
        "            results.append([url_id, url, pos_score, neg_score, polarity, subjectivity, avg_sent_length,\n",
        "                            perc_complex, fog, complex_count, word_count, pronoun_count, avg_word_length])\n",
        "    return results"
      ],
      "metadata": {
        "id": "78tkuiljZbDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "results: Stores the computed metrics for each URL.\n",
        "\n",
        "input_df.iterrows(): Iterates over each row in the input DataFrame.\n",
        "\n",
        "extract_text(url): Extracts article text.\n",
        "\n",
        "clean_text(text): Cleans the text.\n",
        "\n",
        "analyze_sentiment(words): Computes sentiment scores.\n",
        "\n",
        "compute_readability(text): Computes readability metrics.\n",
        "\n",
        "extract_personal_pronouns(text): Counts personal pronouns.\n",
        "\n",
        "avg_word_length: Calculates the average word length."
      ],
      "metadata": {
        "id": "ZloyJneKF7WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run analysis and save to Excel\n",
        "output_df = pd.DataFrame(analyze_articles(), columns=[\n",
        "    'URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
        "    'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'COMPLEX WORD COUNT',\n",
        "    'WORD COUNT', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'\n",
        "])\n",
        "output_df.to_excel(\"Output.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "WGPXqAieZeGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pd.DataFrame(...): Creates a DataFrame from the results.\n",
        "\n",
        "output_df.to_excel(...): Saves the DataFrame to an Excel file."
      ],
      "metadata": {
        "id": "ZGLdeqgqGHjj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rw3j0l0GBPnX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}